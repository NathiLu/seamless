{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"HuFo System This is the documentation for the combined Ambisonics and WFS system at Humboldt Forum , Berlin. It provides basic information and guidelines for artists, as well as extended instructions for engineers and system administrators. If you want to know more about the concept, continue here: Concept If you are interested in using the system from a Reaper session, continue here: Reaper Userguide All software components are organized in a dedicated repository: HuFo System 2021 - TU Studio Team: Henrik von Coler Paul Schuladen Nils Tonn\u00e4tt","title":"HuFo System"},{"location":"#hufo-system","text":"This is the documentation for the combined Ambisonics and WFS system at Humboldt Forum , Berlin. It provides basic information and guidelines for artists, as well as extended instructions for engineers and system administrators. If you want to know more about the concept, continue here: Concept If you are interested in using the system from a Reaper session, continue here: Reaper Userguide","title":"HuFo System"},{"location":"#all-software-components-are-organized-in-a-dedicated-repository-hufo-system","text":"2021 - TU Studio Team: Henrik von Coler Paul Schuladen Nils Tonn\u00e4tt","title":"All software components are organized in a dedicated repository: HuFo System"},{"location":"about/","text":"About the System Concept The Ethnomusicology Museum at the newly built Humboldt Forum features a listening room for immersive illustration of relevant auditory content. It is unique in that it combines multiple methods for sound field synthesis, mainly Wave Field Synthesis (WFS) and Higher Order Ambisonics (HOA), thus providing an enhanced spatial experience. A dedicated software system, developed by the Audiocommunication Group at TU Berlin, allows a seamless integration of these methods. Loudspeaker Configuration The listening room features 32 WFS panels by Four Audio . This results in a total of 256 WFS channels, using 768 tweeters and 64 woofers. Both arcs hold 16 panels each, mounted as a continuous ribbon above head height with a horizontal speaker distance of 10 cm. 45 Genelec 8020C speakers are arranged in three levels on each arc, used for Ambisonics rendering. Top view of the listening room with the entrances (left,right) and two arcs, each with a ribbon of WFS panels (gray). Side view of a single arc with the ribbon of WFS panels (gray) and the Ambisonics speakers (black). Fundamentals of Spatialization The Virtual Sound Source The combined system works with so called virtual sound sources , also referred to as the object oriented approach of sound spatialization. The figure below shows the model of such such a virtual sound source, which is defined by its position, using two angles, the distance and a source width. Every sound event in a project or composition can be connected to such a virtual sound source, allowing to place it in the listening space. Depending on the preferred workflow, different tools can be used for a dynamic arrangement of the individual sound sources. The provided tools in Reaper grant a quick entry by providing control through simple automation trajectories in a DAW project. The Send-System In addition to the position of the virtual sound source, the proposed approach also allows the continuous fade of sound events between the Ambisonics and the WFS rendering through a send system.","title":"About the System"},{"location":"about/#about-the-system","text":"","title":"About the System"},{"location":"about/#concept","text":"The Ethnomusicology Museum at the newly built Humboldt Forum features a listening room for immersive illustration of relevant auditory content. It is unique in that it combines multiple methods for sound field synthesis, mainly Wave Field Synthesis (WFS) and Higher Order Ambisonics (HOA), thus providing an enhanced spatial experience. A dedicated software system, developed by the Audiocommunication Group at TU Berlin, allows a seamless integration of these methods.","title":"Concept"},{"location":"about/#loudspeaker-configuration","text":"The listening room features 32 WFS panels by Four Audio . This results in a total of 256 WFS channels, using 768 tweeters and 64 woofers. Both arcs hold 16 panels each, mounted as a continuous ribbon above head height with a horizontal speaker distance of 10 cm. 45 Genelec 8020C speakers are arranged in three levels on each arc, used for Ambisonics rendering. Top view of the listening room with the entrances (left,right) and two arcs, each with a ribbon of WFS panels (gray). Side view of a single arc with the ribbon of WFS panels (gray) and the Ambisonics speakers (black).","title":"Loudspeaker Configuration"},{"location":"about/#fundamentals-of-spatialization","text":"","title":"Fundamentals of Spatialization"},{"location":"about/#the-virtual-sound-source","text":"The combined system works with so called virtual sound sources , also referred to as the object oriented approach of sound spatialization. The figure below shows the model of such such a virtual sound source, which is defined by its position, using two angles, the distance and a source width. Every sound event in a project or composition can be connected to such a virtual sound source, allowing to place it in the listening space. Depending on the preferred workflow, different tools can be used for a dynamic arrangement of the individual sound sources. The provided tools in Reaper grant a quick entry by providing control through simple automation trajectories in a DAW project.","title":"The Virtual Sound Source"},{"location":"about/#the-send-system","text":"In addition to the position of the virtual sound source, the proposed approach also allows the continuous fade of sound events between the Ambisonics and the WFS rendering through a send system.","title":"The Send-System"},{"location":"oscrouter/","text":"OSC-Router and Processor The OSC-Router written in python serves as central interface for OSC-messages in a multiclient spatial rendering environment. It automatically translates incoming OSC-messages to match the expected formats of the rendering-engines and distributes it to all connected clients including UI-Clients and Data-clients for automation data. (Here Ircams OSCar). OSC-Router config The OSC-Router is started by executing the MAIN_oscrouter.py . Per default it loads the configurationfile oscRouterConfig.txt in the same folder. With the argument --config another file can be loaded. The configfile consists of a number of blocks which are divided with *** . For more information have a look at configSampe.txt It provides an additional debug option: using the option --oscdebug followed by a string with ip and port (e.g. --oscdebug \"192.168.3.2 55112\" ) an additional OSC-listener can be defined, which receives a copy of every OSC-message sent out by the OSC-router. accepted OSC messages The Osc-Router accepts various message formats and take care of converting them to the right format. Every OSC-Message consists of a OSC-Address Prefix followed by a number of values. Here we only work with integer- (i) and float-values (f) Source IDs begins with Index 1 and can go up to 64. The following examples demonstrate which OSC-Messages are accepted for position data. Source ID can be in the OSC-Prefix /source/1/aed f f f with f f f = azimuth elevation distance Or part of the Message-Values /source/xyz i f f f with i f f f = sID x y z The last component of the OSC-Prefix defines the coordinate format. Besides full sets of coordinates single coordinate values can be send too /source/azim i f , /source/1/x f as well as pairs /source/1/ad f f , /source/xy i f f Polar and Cartesian formats will automatically converted according to the target renderer. A gain-send value has to be given which is the amount of audio sent to a specific rendering module (e.g. Ambisonics, WFS). /source/send/spatial i i f with i i f = sourceID renderingID gain(linear) A direct-send to a speaker can be given: '/source/send/direct i i f' with i i f = sourceID outputID gain(linear) (0 = Subwoofer) Settubg render-specific attributes: /source/doppler i i with i i = sourceID 0/1 /source/planewvae i i with i i = sourceID 0/1","title":"OSC Router"},{"location":"oscrouter/#osc-router-and-processor","text":"The OSC-Router written in python serves as central interface for OSC-messages in a multiclient spatial rendering environment. It automatically translates incoming OSC-messages to match the expected formats of the rendering-engines and distributes it to all connected clients including UI-Clients and Data-clients for automation data. (Here Ircams OSCar).","title":"OSC-Router and Processor"},{"location":"oscrouter/#osc-router-config","text":"The OSC-Router is started by executing the MAIN_oscrouter.py . Per default it loads the configurationfile oscRouterConfig.txt in the same folder. With the argument --config another file can be loaded. The configfile consists of a number of blocks which are divided with *** . For more information have a look at configSampe.txt It provides an additional debug option: using the option --oscdebug followed by a string with ip and port (e.g. --oscdebug \"192.168.3.2 55112\" ) an additional OSC-listener can be defined, which receives a copy of every OSC-message sent out by the OSC-router.","title":"OSC-Router config"},{"location":"oscrouter/#accepted-osc-messages","text":"The Osc-Router accepts various message formats and take care of converting them to the right format. Every OSC-Message consists of a OSC-Address Prefix followed by a number of values. Here we only work with integer- (i) and float-values (f) Source IDs begins with Index 1 and can go up to 64. The following examples demonstrate which OSC-Messages are accepted for position data. Source ID can be in the OSC-Prefix /source/1/aed f f f with f f f = azimuth elevation distance Or part of the Message-Values /source/xyz i f f f with i f f f = sID x y z The last component of the OSC-Prefix defines the coordinate format. Besides full sets of coordinates single coordinate values can be send too /source/azim i f , /source/1/x f as well as pairs /source/1/ad f f , /source/xy i f f Polar and Cartesian formats will automatically converted according to the target renderer. A gain-send value has to be given which is the amount of audio sent to a specific rendering module (e.g. Ambisonics, WFS). /source/send/spatial i i f with i i f = sourceID renderingID gain(linear) A direct-send to a speaker can be given: '/source/send/direct i i f' with i i f = sourceID outputID gain(linear) (0 = Subwoofer) Settubg render-specific attributes: /source/doppler i i with i i = sourceID 0/1 /source/planewvae i i with i i = sourceID 0/1","title":"accepted OSC messages"},{"location":"reaper/","text":"Working with Reaper The most accessible way of using the HuFo system is a single DAW session from a laptop, just as working with any other multi-track audio project. Reaper is used as the standard software in most projects and recommended. Other solutions are possible but not fully tested. Each audio track in a Reaper project is directly routed to the system with DANTE and connected to a virtual sound source. Source position and additional properties can be controlled and automated as any other parameter. This workflow ensures that content can be prepared in advance and ported to the system afterwards. Audio-Sources in general An audio-source in a spatial audio-system is defined by the audio content and the source attributes, like the position of the source. Depending on the used rendering-module in the HuFo-System (WFS, Ambisonics, Reverb) additional attributes can be defined, e.g. plane wave and Doppler effect for the WFS module. The rendering modules are running parallel for all sources. Which rendering module is used can be determined with the additional \"send to\" parameters, which control the amount of the audio-signal being sent to a specific rendering module. In that way a fades from on to another system as well as mixtures can be realized. By definition all Audio-Sources are Mono-Audio sources and best results in spatial precision are achieved by sending all audio-element to a single audio source. Of course stereo or other multichannel material can be used too, by using audio sources as virtual speakers which are rendered by the system. Audio Sources in REAPER For defining an audio-source in REAPER, a Plugin is used for sending the source attributes via OSC synchronized to the audio playback (here OSCar by IRCAM is used). Every audio source is identified by an ID (1-64) which is set in the plugin and corresponds to the channel the audio is sent out. This also means every instance of the plugins represents one audio source. The output of the audio tracks should be set be sent to a mono channel, either as direct hardware output or if you are using bus-systems to a mono channel on the bus-track. Content Production Process In the production process the automation data can either be written with the pencil tool inside of REAPER. Also a dedicated interface-client or hardware controllers can be used, which connect also to the central OSC router. The OSC messages are then distributed to the REAPER-plugin where it can be written using the Reaper's automation modes. Since it is not defined which state the sources have at the beginning of the playback all source-attributes must be set at the beginning of the project. For more information about the OSC-Data have a look in the chapter OSC-Router. Content Playback The result of a production is a multichannel audio file in which the plugin automation data will be embedded with REAPER's Take FX function. This file including the automations will be saved in Reaper Project Bay from it then can be pasted and arranged in a playback project. For the project-export a Reaperscript is provided which automates the rendering and data-embedding process.","title":"Reaper User Guide"},{"location":"reaper/#working-with-reaper","text":"The most accessible way of using the HuFo system is a single DAW session from a laptop, just as working with any other multi-track audio project. Reaper is used as the standard software in most projects and recommended. Other solutions are possible but not fully tested. Each audio track in a Reaper project is directly routed to the system with DANTE and connected to a virtual sound source. Source position and additional properties can be controlled and automated as any other parameter. This workflow ensures that content can be prepared in advance and ported to the system afterwards.","title":"Working with Reaper"},{"location":"reaper/#audio-sources-in-general","text":"An audio-source in a spatial audio-system is defined by the audio content and the source attributes, like the position of the source. Depending on the used rendering-module in the HuFo-System (WFS, Ambisonics, Reverb) additional attributes can be defined, e.g. plane wave and Doppler effect for the WFS module. The rendering modules are running parallel for all sources. Which rendering module is used can be determined with the additional \"send to\" parameters, which control the amount of the audio-signal being sent to a specific rendering module. In that way a fades from on to another system as well as mixtures can be realized. By definition all Audio-Sources are Mono-Audio sources and best results in spatial precision are achieved by sending all audio-element to a single audio source. Of course stereo or other multichannel material can be used too, by using audio sources as virtual speakers which are rendered by the system.","title":"Audio-Sources in general"},{"location":"reaper/#audio-sources-in-reaper","text":"For defining an audio-source in REAPER, a Plugin is used for sending the source attributes via OSC synchronized to the audio playback (here OSCar by IRCAM is used). Every audio source is identified by an ID (1-64) which is set in the plugin and corresponds to the channel the audio is sent out. This also means every instance of the plugins represents one audio source. The output of the audio tracks should be set be sent to a mono channel, either as direct hardware output or if you are using bus-systems to a mono channel on the bus-track.","title":"Audio Sources  in REAPER"},{"location":"reaper/#content-production-process","text":"In the production process the automation data can either be written with the pencil tool inside of REAPER. Also a dedicated interface-client or hardware controllers can be used, which connect also to the central OSC router. The OSC messages are then distributed to the REAPER-plugin where it can be written using the Reaper's automation modes. Since it is not defined which state the sources have at the beginning of the playback all source-attributes must be set at the beginning of the project. For more information about the OSC-Data have a look in the chapter OSC-Router.","title":"Content Production Process"},{"location":"reaper/#content-playback","text":"The result of a production is a multichannel audio file in which the plugin automation data will be embedded with REAPER's Take FX function. This file including the automations will be saved in Reaper Project Bay from it then can be pasted and arranged in a playback project. For the project-export a Reaperscript is provided which automates the rendering and data-embedding process.","title":"Content Playback"},{"location":"signalflow/","text":"Signal Flow The following flow chart visualizes the interconnection between the software components. Scroll down to get the exact input and output assignment. Input-Output Assignment Linux: MAIN (DANTE) Inputs Source 1-64 Source channels from media machine. Outputs Target 1-22 DAC 1 (Ambisonics speakers 1-22) 23-44 DAC 2 (Ambisonics speakers 23-44) 45 DAC 1 (Ambisonics spekaer 45) 46-47 DAC 1 (SUB 1-2) 48-49 DAC 2 (SUB 3-4)","title":"Signal Flow"},{"location":"signalflow/#signal-flow","text":"The following flow chart visualizes the interconnection between the software components. Scroll down to get the exact input and output assignment.","title":"Signal Flow"},{"location":"signalflow/#input-output-assignment","text":"","title":"Input-Output Assignment"},{"location":"signalflow/#linux-main-dante","text":"Inputs Source 1-64 Source channels from media machine. Outputs Target 1-22 DAC 1 (Ambisonics speakers 1-22) 23-44 DAC 2 (Ambisonics speakers 23-44) 45 DAC 1 (Ambisonics spekaer 45) 46-47 DAC 1 (SUB 1-2) 48-49 DAC 2 (SUB 3-4)","title":"Linux: MAIN (DANTE)"},{"location":"supercollider/","text":"SuperCollider Mixing and signal distribution is based on SuperCollider. Two main scripts are used: HuFo_SERVER.scd HuFo_SERVER is a mixing and distribution instance for the source signals, as well as for Ambisonics encoding. HuFo_WFS.scd HuFo_WFS is a mixing and distribution instance for the source signals, limited to WFS for. Both instances are take the same optional input arguments: $ sclang HuFo_SERVER.scd <N_inputs> <server_port> $ sclang HuFo_WFS.scd <N_inputs> <server_port> Defaults: N_inputs: 64 server_port: 58010 Setting Up Build Decoders Decoders in ADT have a problem for more than speakers 24? speakers. Use standalone decoder in that case. Install Decoders Copy the directory decoders to the SC user extension directory. It can be obtained in SC: Platform.userExtensionDir For larger loudspeaker setups (<24), standalone Jack decoders are used. SuperCollider OSC Paths The sueprcollider mixer listens to several OSC messages for signal routing and conrolling positions Sends To Ambisonics + WFS /source/send/spatial i i f first argument = channel ID second argument = system ID 0 = Ambisonics (inside SC) 1 = WFS (external, WONDER) To Subwoofer /source/send/direct i i f first argument = channel ID second argument = output ID 0 = Subwoofer Ambisonics Spatial Control /source/pos/azim i f first argument = channel ID second argument = angle (rad) /source/pos/elev i f first argument = channel ID second argument = angle (rad) /source/pos/dist i f first argument = channel ID second argument = distance (meters) /source/pos/aed i f f f first argument = channel ID second argument = azimuth (degree) third argument = elevation (degree) fourth argument = distance (meters)","title":"SuperCollider"},{"location":"supercollider/#supercollider","text":"Mixing and signal distribution is based on SuperCollider. Two main scripts are used:","title":"SuperCollider"},{"location":"supercollider/#hufo_serverscd","text":"HuFo_SERVER is a mixing and distribution instance for the source signals, as well as for Ambisonics encoding.","title":"HuFo_SERVER.scd"},{"location":"supercollider/#hufo_wfsscd","text":"HuFo_WFS is a mixing and distribution instance for the source signals, limited to WFS for. Both instances are take the same optional input arguments: $ sclang HuFo_SERVER.scd <N_inputs> <server_port> $ sclang HuFo_WFS.scd <N_inputs> <server_port> Defaults: N_inputs: 64 server_port: 58010","title":"HuFo_WFS.scd"},{"location":"supercollider/#setting-up","text":"","title":"Setting Up"},{"location":"supercollider/#build-decoders","text":"Decoders in ADT have a problem for more than speakers 24? speakers. Use standalone decoder in that case.","title":"Build Decoders"},{"location":"supercollider/#install-decoders","text":"Copy the directory decoders to the SC user extension directory. It can be obtained in SC: Platform.userExtensionDir For larger loudspeaker setups (<24), standalone Jack decoders are used.","title":"Install Decoders"},{"location":"supercollider/#supercollider-osc-paths","text":"The sueprcollider mixer listens to several OSC messages for signal routing and conrolling positions","title":"SuperCollider OSC Paths"},{"location":"supercollider/#sends","text":"","title":"Sends"},{"location":"supercollider/#to-ambisonics-wfs","text":"/source/send/spatial i i f first argument = channel ID second argument = system ID 0 = Ambisonics (inside SC) 1 = WFS (external, WONDER)","title":"To Ambisonics + WFS"},{"location":"supercollider/#to-subwoofer","text":"/source/send/direct i i f first argument = channel ID second argument = output ID 0 = Subwoofer","title":"To Subwoofer"},{"location":"supercollider/#ambisonics-spatial-control","text":"/source/pos/azim i f first argument = channel ID second argument = angle (rad) /source/pos/elev i f first argument = channel ID second argument = angle (rad) /source/pos/dist i f first argument = channel ID second argument = distance (meters) /source/pos/aed i f f f first argument = channel ID second argument = azimuth (degree) third argument = elevation (degree) fourth argument = distance (meters)","title":"Ambisonics Spatial Control"},{"location":"system_setup/","text":"Setting up the System Python Dependencies pip3 install oscpy SuperCollider 1: Build and install SC 2: Build a headless version of SC: Follow https://github.com/supercollider/supercollider/blob/develop/README_LINUX.md but call cmake: cmake -DCMAKE_BUILD_TYPE=Release -DNATIVE=ON -DSC_EL=no -DSC_ABLETON_LINK=off -NO_X11=ON -DSC_QT=OFF .. Install SC3-Plugins: https://github.com/supercollider/sc3-plugins Install SC-HOA classes: Quarks.install(\"https://github.com/florian-grond/SC-HOA\") Developer Mode The scripts supercollider_gui.sh and supercollider_nogui.sh allow to switch between the standard SC install and the headless version by setting symlinks in /usr/local/bin Once the standard version is lionked, scide can be started for development and debugging. System Services copy all services to: /usr/lib/systemd/system Disable Automatic Updates Automatic updates are not desired, since they can change the system behavior. In addition can disable the DANTE drivers. Edit: /etc/apt/apt.conf.d/20auto-upgrades It needs to be: APT::Periodic::Update-Package-Lists \"0\"; APT::Periodic::Download-Upgradeable-Packages \"0\"; APT::Periodic::AutocleanInterval \"0\"; APT::Periodic::Unattended-Upgrade \"1\";","title":"System Setup"},{"location":"system_setup/#setting-up-the-system","text":"","title":"Setting up the System"},{"location":"system_setup/#python-dependencies","text":"pip3 install oscpy","title":"Python Dependencies"},{"location":"system_setup/#supercollider","text":"1: Build and install SC 2: Build a headless version of SC: Follow https://github.com/supercollider/supercollider/blob/develop/README_LINUX.md but call cmake: cmake -DCMAKE_BUILD_TYPE=Release -DNATIVE=ON -DSC_EL=no -DSC_ABLETON_LINK=off -NO_X11=ON -DSC_QT=OFF .. Install SC3-Plugins: https://github.com/supercollider/sc3-plugins Install SC-HOA classes: Quarks.install(\"https://github.com/florian-grond/SC-HOA\")","title":"SuperCollider"},{"location":"system_setup/#developer-mode","text":"The scripts supercollider_gui.sh and supercollider_nogui.sh allow to switch between the standard SC install and the headless version by setting symlinks in /usr/local/bin Once the standard version is lionked, scide can be started for development and debugging.","title":"Developer Mode"},{"location":"system_setup/#system-services","text":"copy all services to: /usr/lib/systemd/system","title":"System Services"},{"location":"system_setup/#disable-automatic-updates","text":"Automatic updates are not desired, since they can change the system behavior. In addition can disable the DANTE drivers. Edit: /etc/apt/apt.conf.d/20auto-upgrades It needs to be: APT::Periodic::Update-Package-Lists \"0\"; APT::Periodic::Download-Upgradeable-Packages \"0\"; APT::Periodic::AutocleanInterval \"0\"; APT::Periodic::Unattended-Upgrade \"1\";","title":"Disable Automatic Updates"},{"location":"userguide/","text":"","title":"Userguide"}]}